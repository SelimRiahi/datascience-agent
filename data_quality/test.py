import pandas as pd
import numpy as np

def validate_cleaning_results(original_file_path, cleaned_file_path):
    """Validate manually what the LLM agent actually removed"""
    
    print("üîç VALIDATION MANUELLE DES R√âSULTATS DE NETTOYAGE")
    print("=" * 60)
    
    # Load both files
    df_original = pd.read_excel(original_file_path)
    df_cleaned = pd.read_excel(cleaned_file_path)
    
    print(f"üìä Donn√©es originales: {len(df_original)} lignes")
    print(f"üìä Donn√©es nettoy√©es: {len(df_cleaned)} lignes")
    print(f"üìä Diff√©rence: {len(df_original) - len(df_cleaned)} lignes supprim√©es")
    print()
    
    # Check Description column specifically
    print("üîç ANALYSE DE LA COLONNE DESCRIPTION:")
    print("-" * 40)
    
    # Count different types of missing/empty values in original
    desc_col = df_original['Description']
    
    # Various ways to check for empty/missing
    null_count = desc_col.isnull().sum()
    empty_string_count = (desc_col == '').sum()
    whitespace_only_count = desc_col.astype(str).str.strip().eq('').sum() - empty_string_count
    nan_string_count = desc_col.astype(str).str.lower().eq('nan').sum()
    
    print(f"Valeurs NULL (pd.isnull()): {null_count}")
    print(f"Cha√Ænes vides (''): {empty_string_count}")
    print(f"Espaces uniquement: {whitespace_only_count}")
    print(f"Cha√Ænes 'nan': {nan_string_count}")
    
    # Total problematic descriptions
    problematic_mask = (
        desc_col.isnull() | 
        (desc_col == '') | 
        (desc_col.astype(str).str.strip() == '') |
        (desc_col.astype(str).str.lower() == 'nan')
    )
    
    total_problematic = problematic_mask.sum()
    print(f"üìç TOTAL probl√©matique: {total_problematic}")
    print()
    
    # Check what was actually removed
    print("üîç V√âRIFICATION DE CE QUI A √âT√â SUPPRIM√â:")
    print("-" * 45)
    
    if total_problematic == (len(df_original) - len(df_cleaned)):
        print("‚úÖ CORRESPONDANCE PARFAITE!")
        print(f"   LLM a supprim√© exactement les {total_problematic} descriptions vides/manquantes")
    else:
        print("‚ùå DIFF√âRENCE D√âTECT√âE!")
        print(f"   Descriptions probl√©matiques: {total_problematic}")
        print(f"   Lignes supprim√©es par LLM: {len(df_original) - len(df_cleaned)}")
        print("   Investigation suppl√©mentaire n√©cessaire...")
    
    print()
    
    # Show sample of problematic descriptions
    print("üìã √âCHANTILLON DES DESCRIPTIONS PROBL√âMATIQUES:")
    print("-" * 50)
    
    problematic_rows = df_original[problematic_mask]
    if len(problematic_rows) > 0:
        sample_size = min(10, len(problematic_rows))
        print(f"Affichage des {sample_size} premi√®res sur {len(problematic_rows)}:")
        
        for i, (idx, row) in enumerate(problematic_rows.head(sample_size).iterrows()):
            desc_value = row['Description']
            desc_repr = repr(desc_value)  # Shows actual representation
            print(f"  {i+1:2d}. Index {idx}: {desc_repr}")
    
    print()
    
    # Check other columns for completeness
    print("üîç V√âRIFICATION AUTRES COLONNES:")
    print("-" * 35)
    
    for col in df_original.columns:
        if col != 'Description':
            original_nulls = df_original[col].isnull().sum()
            cleaned_nulls = df_cleaned[col].isnull().sum() if col in df_cleaned.columns else 0
            
            if original_nulls > 0:
                print(f"{col}: {original_nulls} nulls originaux ‚Üí {cleaned_nulls} nulls nettoy√©s")
    
    print()
    
    # Final verification
    print("üéØ CONCLUSION:")
    print("-" * 12)
    
    if total_problematic == 1454:
        print("‚úÖ LLM √©tait CORRECT: exactement 1454 descriptions vides √† supprimer")
    else:
        print(f"‚ö†Ô∏è  Diff√©rence: LLM dit 1454, mais nous trouvons {total_problematic}")
    
    return {
        'original_rows': len(df_original),
        'cleaned_rows': len(df_cleaned),
        'rows_removed': len(df_original) - len(df_cleaned),
        'problematic_descriptions': total_problematic,
        'llm_accurate': total_problematic == 1454
    }

# Script de validation
if __name__ == "__main__":
    # Paths to your files
    original_path = r"C:\Users\Selim\OneDrive\Bureau\data science agent\data\data.xlsx"
    cleaned_path = r"C:\Users\Selim\OneDrive\Bureau\data science agent\data\data_cleaned.xlsx"
    
    try:
        results = validate_cleaning_results(original_path, cleaned_path)
        
        print("\n" + "=" * 60)
        print("üìà R√âSUM√â DE VALIDATION")
        print("=" * 60)
        print(f"Exactitude du LLM: {'OUI' if results['llm_accurate'] else 'NON'}")
        print(f"Lignes supprim√©es: {results['rows_removed']}")
        print(f"Descriptions probl√©matiques d√©tect√©es: {results['problematic_descriptions']}")
        
    except Exception as e:
        print(f"‚ùå Erreur lors de la validation: {e}")